{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Importing dependencies for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ad\\Anaconda3\\envs\\newenvt\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting class names for the dataset\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       [[[ 28,  25,  10],\n",
       "         [ 37,  34,  19],\n",
       "         [ 38,  35,  20],\n",
       "         ...,\n",
       "         [ 76,  67,  39],\n",
       "         [ 81,  72,  43],\n",
       "         [ 85,  76,  47]],\n",
       "\n",
       "        [[ 33,  28,  13],\n",
       "         [ 34,  30,  14],\n",
       "         [ 32,  27,  12],\n",
       "         ...,\n",
       "         [ 95,  82,  55],\n",
       "         [ 96,  82,  56],\n",
       "         [ 85,  72,  45]],\n",
       "\n",
       "        [[ 39,  32,  15],\n",
       "         [ 40,  33,  17],\n",
       "         [ 57,  50,  33],\n",
       "         ...,\n",
       "         [ 93,  76,  52],\n",
       "         [107,  89,  66],\n",
       "         [ 95,  77,  54]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 83,  73,  52],\n",
       "         [ 87,  77,  56],\n",
       "         [ 84,  74,  52],\n",
       "         ...,\n",
       "         [ 99,  93,  70],\n",
       "         [ 90,  84,  61],\n",
       "         [ 81,  75,  52]],\n",
       "\n",
       "        [[ 88,  72,  51],\n",
       "         [ 90,  74,  52],\n",
       "         [ 93,  77,  56],\n",
       "         ...,\n",
       "         [ 80,  74,  53],\n",
       "         [ 76,  70,  49],\n",
       "         [ 82,  76,  55]],\n",
       "\n",
       "        [[ 97,  78,  56],\n",
       "         [ 94,  75,  53],\n",
       "         [ 93,  75,  53],\n",
       "         ...,\n",
       "         [ 54,  47,  28],\n",
       "         [ 63,  56,  37],\n",
       "         [ 72,  65,  46]]],\n",
       "\n",
       "\n",
       "       [[[170, 180, 198],\n",
       "         [168, 178, 196],\n",
       "         [177, 185, 203],\n",
       "         ...,\n",
       "         [162, 179, 215],\n",
       "         [158, 178, 214],\n",
       "         [157, 177, 212]],\n",
       "\n",
       "        [[168, 181, 198],\n",
       "         [172, 185, 201],\n",
       "         [171, 183, 200],\n",
       "         ...,\n",
       "         [159, 177, 212],\n",
       "         [156, 176, 211],\n",
       "         [154, 174, 209]],\n",
       "\n",
       "        [[154, 170, 186],\n",
       "         [149, 165, 181],\n",
       "         [129, 144, 162],\n",
       "         ...,\n",
       "         [161, 178, 214],\n",
       "         [157, 177, 212],\n",
       "         [154, 174, 209]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 74,  84,  80],\n",
       "         [ 76,  85,  81],\n",
       "         [ 78,  85,  82],\n",
       "         ...,\n",
       "         [ 71,  75,  78],\n",
       "         [ 68,  72,  75],\n",
       "         [ 61,  65,  68]],\n",
       "\n",
       "        [[ 68,  76,  77],\n",
       "         [ 69,  77,  78],\n",
       "         [ 72,  79,  78],\n",
       "         ...,\n",
       "         [ 76,  80,  83],\n",
       "         [ 71,  75,  78],\n",
       "         [ 71,  75,  78]],\n",
       "\n",
       "        [[ 67,  75,  78],\n",
       "         [ 68,  76,  79],\n",
       "         [ 69,  75,  76],\n",
       "         ...,\n",
       "         [ 75,  79,  82],\n",
       "         [ 71,  75,  78],\n",
       "         [ 73,  77,  80]]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313725, 0.24705882],\n",
       "         [0.16862745, 0.18039216, 0.17647059],\n",
       "         [0.19607843, 0.18823529, 0.16862745],\n",
       "         ...,\n",
       "         [0.61960784, 0.51764706, 0.42352941],\n",
       "         [0.59607843, 0.49019608, 0.4       ],\n",
       "         [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843137, 0.07843137],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509804, 0.21568627],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215686, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941176, 0.19607843],\n",
       "         [0.47058824, 0.32941176, 0.19607843],\n",
       "         [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81568627, 0.66666667, 0.37647059],\n",
       "         [0.78823529, 0.6       , 0.13333333],\n",
       "         [0.77647059, 0.63137255, 0.10196078],\n",
       "         ...,\n",
       "         [0.62745098, 0.52156863, 0.2745098 ],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "        [[0.70588235, 0.54509804, 0.37647059],\n",
       "         [0.67843137, 0.48235294, 0.16470588],\n",
       "         [0.72941176, 0.56470588, 0.11764706],\n",
       "         ...,\n",
       "         [0.72156863, 0.58039216, 0.36862745],\n",
       "         [0.38039216, 0.24313725, 0.13333333],\n",
       "         [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "        [[0.69411765, 0.56470588, 0.45490196],\n",
       "         [0.65882353, 0.50588235, 0.36862745],\n",
       "         [0.70196078, 0.55686275, 0.34117647],\n",
       "         ...,\n",
       "         [0.84705882, 0.72156863, 0.54901961],\n",
       "         [0.59215686, 0.4627451 , 0.32941176],\n",
       "         [0.48235294, 0.36078431, 0.28235294]]],\n",
       "\n",
       "\n",
       "       [[[0.60392157, 0.69411765, 0.73333333],\n",
       "         [0.49411765, 0.5372549 , 0.53333333],\n",
       "         [0.41176471, 0.40784314, 0.37254902],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254902, 0.27843137],\n",
       "         [0.34117647, 0.35294118, 0.27843137],\n",
       "         [0.30980392, 0.31764706, 0.2745098 ]],\n",
       "\n",
       "        [[0.54901961, 0.62745098, 0.6627451 ],\n",
       "         [0.56862745, 0.6       , 0.60392157],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.37647059, 0.38823529, 0.30588235],\n",
       "         [0.30196078, 0.31372549, 0.24313725],\n",
       "         [0.27843137, 0.28627451, 0.23921569]],\n",
       "\n",
       "        [[0.54901961, 0.60784314, 0.64313725],\n",
       "         [0.54509804, 0.57254902, 0.58431373],\n",
       "         [0.45098039, 0.45098039, 0.43921569],\n",
       "         ...,\n",
       "         [0.30980392, 0.32156863, 0.25098039],\n",
       "         [0.26666667, 0.2745098 , 0.21568627],\n",
       "         [0.2627451 , 0.27058824, 0.21568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.68627451, 0.65490196, 0.65098039],\n",
       "         [0.61176471, 0.60392157, 0.62745098],\n",
       "         [0.60392157, 0.62745098, 0.66666667],\n",
       "         ...,\n",
       "         [0.16470588, 0.13333333, 0.14117647],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.36470588, 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705882, 0.60392157, 0.50196078],\n",
       "         [0.61176471, 0.59607843, 0.50980392],\n",
       "         [0.62352941, 0.63137255, 0.55686275],\n",
       "         ...,\n",
       "         [0.40392157, 0.36470588, 0.37647059],\n",
       "         [0.48235294, 0.44705882, 0.47058824],\n",
       "         [0.51372549, 0.4745098 , 0.51372549]],\n",
       "\n",
       "        [[0.63921569, 0.58039216, 0.47058824],\n",
       "         [0.61960784, 0.58039216, 0.47843137],\n",
       "         [0.63921569, 0.61176471, 0.52156863],\n",
       "         ...,\n",
       "         [0.56078431, 0.52156863, 0.54509804],\n",
       "         [0.56078431, 0.5254902 , 0.55686275],\n",
       "         [0.56078431, 0.52156863, 0.56470588]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313725, 0.47058824, 0.43921569],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.41176471, 0.43921569, 0.41568627],\n",
       "         ...,\n",
       "         [0.28235294, 0.31764706, 0.31372549],\n",
       "         [0.28235294, 0.31372549, 0.30980392],\n",
       "         [0.28235294, 0.31372549, 0.30980392]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666667, 0.29411765, 0.28627451],\n",
       "         [0.2745098 , 0.29803922, 0.29411765],\n",
       "         [0.30588235, 0.32941176, 0.32156863]],\n",
       "\n",
       "        [[0.41568627, 0.44313725, 0.41176471],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         [0.37254902, 0.4       , 0.36862745],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.3254902 ],\n",
       "         [0.30980392, 0.33333333, 0.3254902 ],\n",
       "         [0.31372549, 0.3372549 , 0.32941176]]],\n",
       "\n",
       "\n",
       "       [[[0.10980392, 0.09803922, 0.03921569],\n",
       "         [0.14509804, 0.13333333, 0.0745098 ],\n",
       "         [0.14901961, 0.1372549 , 0.07843137],\n",
       "         ...,\n",
       "         [0.29803922, 0.2627451 , 0.15294118],\n",
       "         [0.31764706, 0.28235294, 0.16862745],\n",
       "         [0.33333333, 0.29803922, 0.18431373]],\n",
       "\n",
       "        [[0.12941176, 0.10980392, 0.05098039],\n",
       "         [0.13333333, 0.11764706, 0.05490196],\n",
       "         [0.1254902 , 0.10588235, 0.04705882],\n",
       "         ...,\n",
       "         [0.37254902, 0.32156863, 0.21568627],\n",
       "         [0.37647059, 0.32156863, 0.21960784],\n",
       "         [0.33333333, 0.28235294, 0.17647059]],\n",
       "\n",
       "        [[0.15294118, 0.1254902 , 0.05882353],\n",
       "         [0.15686275, 0.12941176, 0.06666667],\n",
       "         [0.22352941, 0.19607843, 0.12941176],\n",
       "         ...,\n",
       "         [0.36470588, 0.29803922, 0.20392157],\n",
       "         [0.41960784, 0.34901961, 0.25882353],\n",
       "         [0.37254902, 0.30196078, 0.21176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3254902 , 0.28627451, 0.20392157],\n",
       "         [0.34117647, 0.30196078, 0.21960784],\n",
       "         [0.32941176, 0.29019608, 0.20392157],\n",
       "         ...,\n",
       "         [0.38823529, 0.36470588, 0.2745098 ],\n",
       "         [0.35294118, 0.32941176, 0.23921569],\n",
       "         [0.31764706, 0.29411765, 0.20392157]],\n",
       "\n",
       "        [[0.34509804, 0.28235294, 0.2       ],\n",
       "         [0.35294118, 0.29019608, 0.20392157],\n",
       "         [0.36470588, 0.30196078, 0.21960784],\n",
       "         ...,\n",
       "         [0.31372549, 0.29019608, 0.20784314],\n",
       "         [0.29803922, 0.2745098 , 0.19215686],\n",
       "         [0.32156863, 0.29803922, 0.21568627]],\n",
       "\n",
       "        [[0.38039216, 0.30588235, 0.21960784],\n",
       "         [0.36862745, 0.29411765, 0.20784314],\n",
       "         [0.36470588, 0.29411765, 0.20784314],\n",
       "         ...,\n",
       "         [0.21176471, 0.18431373, 0.10980392],\n",
       "         [0.24705882, 0.21960784, 0.14509804],\n",
       "         [0.28235294, 0.25490196, 0.18039216]]],\n",
       "\n",
       "\n",
       "       [[[0.66666667, 0.70588235, 0.77647059],\n",
       "         [0.65882353, 0.69803922, 0.76862745],\n",
       "         [0.69411765, 0.7254902 , 0.79607843],\n",
       "         ...,\n",
       "         [0.63529412, 0.70196078, 0.84313725],\n",
       "         [0.61960784, 0.69803922, 0.83921569],\n",
       "         [0.61568627, 0.69411765, 0.83137255]],\n",
       "\n",
       "        [[0.65882353, 0.70980392, 0.77647059],\n",
       "         [0.6745098 , 0.7254902 , 0.78823529],\n",
       "         [0.67058824, 0.71764706, 0.78431373],\n",
       "         ...,\n",
       "         [0.62352941, 0.69411765, 0.83137255],\n",
       "         [0.61176471, 0.69019608, 0.82745098],\n",
       "         [0.60392157, 0.68235294, 0.81960784]],\n",
       "\n",
       "        [[0.60392157, 0.66666667, 0.72941176],\n",
       "         [0.58431373, 0.64705882, 0.70980392],\n",
       "         [0.50588235, 0.56470588, 0.63529412],\n",
       "         ...,\n",
       "         [0.63137255, 0.69803922, 0.83921569],\n",
       "         [0.61568627, 0.69411765, 0.83137255],\n",
       "         [0.60392157, 0.68235294, 0.81960784]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.29019608, 0.32941176, 0.31372549],\n",
       "         [0.29803922, 0.33333333, 0.31764706],\n",
       "         [0.30588235, 0.33333333, 0.32156863],\n",
       "         ...,\n",
       "         [0.27843137, 0.29411765, 0.30588235],\n",
       "         [0.26666667, 0.28235294, 0.29411765],\n",
       "         [0.23921569, 0.25490196, 0.26666667]],\n",
       "\n",
       "        [[0.26666667, 0.29803922, 0.30196078],\n",
       "         [0.27058824, 0.30196078, 0.30588235],\n",
       "         [0.28235294, 0.30980392, 0.30588235],\n",
       "         ...,\n",
       "         [0.29803922, 0.31372549, 0.3254902 ],\n",
       "         [0.27843137, 0.29411765, 0.30588235],\n",
       "         [0.27843137, 0.29411765, 0.30588235]],\n",
       "\n",
       "        [[0.2627451 , 0.29411765, 0.30588235],\n",
       "         [0.26666667, 0.29803922, 0.30980392],\n",
       "         [0.27058824, 0.29411765, 0.29803922],\n",
       "         ...,\n",
       "         [0.29411765, 0.30980392, 0.32156863],\n",
       "         [0.27843137, 0.29411765, 0.30588235],\n",
       "         [0.28627451, 0.30196078, 0.31372549]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd0ada40748>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGdtJREFUeJztnW1sZGd1x//njsfvu+v1vnrf4iUsKkkKG+RGSKlQCi1KEVJAKgg+oHyIWFQRqUhUapRKJZX6AdoC4kNFuzQRoaKElECJqqgliqgipCrgLMkmZCHZpN6sd732eu211++euacf5qZyNs85Ht8Z33F4/j9ptfZz5rnPmWfumTu+/znniKqCEBIfSasdIIS0BgY/IZHC4CckUhj8hEQKg5+QSGHwExIpDH5CIoXBT0ikMPgJiZS2RiaLyJ0AvgGgBOCfVfXL3uM7u3u1p29XI0s2Bck9MTzTP579DUp/Xj4vDRdd/O945v0G6Mb3yrPl9zGH/+4U28uc02B+y9Y7oHG8a1ensDQ/V9dZkDv4RaQE4B8A/BGAUQC/EJHHVfUla05P3y7cec9f5Flrw3MSZ44k+T7wWH6UHfdKmjrHs+cljo8iti0pWWeMfSb53/B25jmzUsPHTmdS2YmQFWezqrJq2tpQCY5r6jyv1Dvf7L2vOs9NE/uYlWo1fLyqfe5YW/Xv//R39pzraORj/20Azqrqa6q6AuARAHc1cDxCSIE0EvwHAZxf8/toNkYIeRvQSPCHPni85YOPiJwQkWERGV6an2tgOUJIM2kk+EcBHF7z+yEAF69/kKqeVNUhVR3q7OltYDlCSDNpJPh/AeCYiBwVkXYAnwLweHPcIoRsNrnv9qtqRUTuBfBfqEl9D6nqr9abl5TCS4onieXRrzwfct7tt27PJ86d3MS5M59nLQBIndvzlsndQ8dFcYwith8dxuvZ5p1y3l45a6m2m7Y0LQfHy6WwCgAA7WVbPejttv3v29Fv2ioombaR0UvB8fllcwo0sfyoP1Ya0vlV9QkATzRyDEJIa+A3/AiJFAY/IZHC4CckUhj8hEQKg5+QSGnobn8eTMUpR3KJl5DiZog5yTbeTMviSW+5VUrnmGmaL1nIwk0i8mRMxw9oWEqreK+Ms1aa2PKbl4iTpuFT3E6AAnra7eMNDuwwbXv27DNtI+cnTBsqK+FxtV+XZnTb4JWfkEhh8BMSKQx+QiKFwU9IpDD4CYmUQu/2i4iZ6JJquJRRNtM4nr9WUaizVJqzDJaL89zyHdNROLwn51w7UsOm3vXGOQcqy1dNW8k5jculcBp5T4c959DAHtPW32enpU9NTZu20Ytjps0q4+UlOjXj7OaVn5BIYfATEikMfkIihcFPSKQw+AmJFAY/IZFSfGKPkbzhS0rGsbyuPDmlPrN1koPT/MWV+jYH6/3cS36xj+bV6fPbaxmnltinnFQXTdv0+Ihp6yw5iThHbg6Ov3PwqDlnT/9207ayZPv42uikaZtedGRMc0+czkyGaSOnPa/8hEQKg5+QSGHwExIpDH5CIoXBT0ikMPgJiZSGpD4RGQFwDUAVQEVVh+qYs6HxPMfKe7z8eK2kipb6jPUcN1yVNW+dxCTcJgtqt60qw9Ycd/YYxwNQmZ8ybXt2hNfbv8euxadqh8XF8XHbNmXLgMvoMG0i4eft51M2fl41Q+f/A1W1BU5CyJaEH/sJiZRGg18B/EREnhWRE81wiBBSDI1+7L9dVS+KyF4AT4rIr1X16bUPyN4UTgBAz45dDS5HCGkWDV35VfVi9v8EgB8BuC3wmJOqOqSqQ509dgkkQkix5A5+EekRkW1v/AzgwwBebJZjhJDNpZGP/fsA/CiT1NoA/Kuq/mfeg7nCXKGy3cZRVysr1ndLNvJaYbkZlY7NK8ZZNZSoBMvmnBLsllx79x4wbbMTRrsrAOnqbHBcYWfZjV2ZN22vXLBlxUW15bzEel0AdCaW1GfLeSvW4TagAOYOflV9DcB7884nhLQWSn2ERAqDn5BIYfATEikMfkIihcFPSKQUXsAzR9JZLrGs0Gw6d6mC318Tq++bV4jT6wmXTwasVsPyWzmxZbmdPfbp2JbYts4u+8tjs7MzwfHLU7Zk98q5K/bxlm2JsNzWbtraUTFt7zoSljErTmHV35y7aBvrhFd+QiKFwU9IpDD4CYkUBj8hkcLgJyRSir/bTzaVFOGadd5de19psa1eIk67kcBzZN9Oc84N++26eq+//Lxpa3MuYdOzc8Hxl18+a86ZW7bv2pfEriXYW7KVjN85esi07du/Pzj+69fOm3MsJWAjGhev/IRECoOfkEhh8BMSKQx+QiKFwU9IpDD4CYkUSn0bwBLLim7I5WO0w3KcTJx6dm1i2zqds+fQrr7g+M3vusGc044l03ahatukakuO8/PhenzL1QlzTqlrj2nb1t1t2m4Z3GfaBg/uNW3nL08Hxy+M2a3B0ibUhuSVn5BIYfATEikMfkIihcFPSKQw+AmJFAY/IZGyrtQnIg8B+CiACVW9JRvrB/B9AIMARgB8UlXDesVbDmiuU9f0ekmSAt/XnHqBXi3BvM/YkxYTw1hyavh1luxicf09dobbwb12ht6NA2G5rG+b3dLqyvikaUsrTpsv56WWNFw7b3Uh3MYLALb32t2kD+wNS5gAsGd7l2mbmbZrBo68fik4vrBs1/1Dyc4urJd6IuTbAO68buw+AE+p6jEAT2W/E0LeRqwb/Kr6NIDr37buAvBw9vPDAD7WZL8IIZtM3s/G+1R1DACy/+2vLxFCtiSb/oexiJwQkWERGV6aD1dVIYQUT97gHxeRAQDI/je/KK2qJ1V1SFWHOnvs5gqEkGLJG/yPA7g7+/luAD9ujjuEkKKoR+r7HoA7AOwWkVEAXwLwZQCPisg9AF4H8Il6F7QKSebJjGu2PJgXz4/N8NE7YsnYSa9d1O4eWzY60G/LV/t32DLgzt7O4LionSXoqbO7du02bYuL9p+Ty0vhbMC5BTsTsK/DPht7xS7SubQYziAEgPFp28fJa4thg9P+q804r9z2atcfY70HqOqnDdOH6l6FELLl4Df8CIkUBj8hkcLgJyRSGPyERAqDn5BIaUEBT0tG8TvGhWfkzJjzMu1yKXPFynmesbscfkn3bu8x5xw70m/a5ifPmbZT//Osaeu948PB8Z077X587e12xl//Hrs45vyMfQ3b3hM+5vyCLX3Oz10zbTPj9n6k6UHTNjlnS5yrEpb0Eidd0Sy6uoFTkVd+QiKFwU9IpDD4CYkUBj8hkcLgJyRSGPyEREqhUp8AKBm938TpCQcJv0d5/co8maS3zZb62tTO2upoD0syqfceavgOAB2GLAcAonZRzXKb0Y8PwJ7t24Lju3fYPeb27bZlwBGnLOuVSbvf3fnz/xsc37HjZnNOuWw/r+4u28dt3Xb2W29XOGMxdU638+fGTNsvT502baOnz5i2Qzf/nmlrS8IZkGnVdrIZ/SF55SckUhj8hEQKg5+QSGHwExIpDH5CIqXYxB4BUqNQm5+kE7Z59eC6Etu2vWTf0d/ba9ezO3hoIDietNt30stlO1nFu9vv3Y72lIB2QwBZdurLzVweN23Vip0AU3YScUbOvRocP3LDAXPOdqe6s3bZeyyJvR/SFt6QsjEOALv3hFuNAcDAgfA5AACzuGr7ofY+JhpuRSZOeK4a1+2NqAC88hMSKQx+QiKFwU9IpDD4CYkUBj8hkcLgJyRS6mnX9RCAjwKYUNVbsrEHAHwWwOXsYfer6hPrHStFgpVSuP1TCeG2SgBQqoaluf4u2/3FSy+btkuzk6ZtcOhW07ZrW1jaKneEEzMAoMORw8TpTyWJneSSiG1rM2TA5Q5bwlxesX2cmbH3yqt3uLC4EByfvHw5OA4AHW22j2nVlsqQ2gLXaiVsS1MnKazDlhVvudVO0En77ISg0St2u660lENxb0JmTz1X/m8DuDMw/nVVPZ79WzfwCSFbi3WDX1WfBjBVgC+EkAJp5G/+e0XktIg8JCI7m+YRIaQQ8gb/NwHcCOA4gDEAX7UeKCInRGRYRIaX5+166ISQYskV/Ko6rqpVVU0BfAvAbc5jT6rqkKoOdfSEq8wQQoonV/CLyNrsho8DeLE57hBCiqIeqe97AO4AsFtERgF8CcAdInIcNcFhBMDn6llMoGZ2U0dqS33vHgy3arphly3JXO2071F2ddptlTq6w1IkAExeuhQcb++wpbLuTlsG7O61W1eV2u15ZccGQz5sa7Nf6vZ2O5uuq9Pej+3bbf9X0/DrPD5uZxC2OfKmrjpSn8PV2bDENrdoZ3auOEstrdoZhBenw/ImALT19Jm2kvW87aXsTFd7ylt9Wu8BqvrpwPCDG1iDELIF4Tf8CIkUBj8hkcLgJyRSGPyERAqDn5BIKbSAZ6JVdFfC3/K76XC/Oe/23z0SHL96IdwSCgAWxE576nBaP62qnVm2tLgaHN/ZYcth7Y6tu9spSulkelWrYT8AYN7wUZ3WTx2d9lolpzXYtm22RDg9OxMcHzPkUgDocrIjl+ftAqQXL9ry4ZmXw+fIctW+7r3jpveYtnLPdtPWsX2XaUvF3uOKIel5iXteRmW98MpPSKQw+AmJFAY/IZHC4CckUhj8hEQKg5+QSClU6hMButrCAsaePjvXf2oiXBjxuVOnzDmjF66YtmPvsQsP7ToQziAEgO5SWPZKOp3Ck51O/7myk51nFC2tHdSW+qw+fokj2YmjG4mbJ2bbFhfDWZorK+G+dAAw4WT8/ealM6bt4qg978Kl6eD41KKdurf3nbbU19fvZTKaJqij26lRgFSdnoxqvWbeQtfBKz8hkcLgJyRSGPyERAqDn5BIYfATEimF3u1XJFiRcL27MyN2wocuhu/YXr5s1/1bKdl39M/N2nepx9NZ09bdFr772tFub+OOHfZd+4F+WwnYUbbv9HaVnLvAafiuvtf+a3Fh0bSlqbOWc2d5YSFcz66jo92cMzMTTgYCgAsXLpi2uTlbQVheCfvf17/XnNPWbd/RX3JCpuLsVeKk6Vj7qKmdjGUJLbqBPl688hMSKQx+QiKFwU9IpDD4CYkUBj8hkcLgJyRS6mnXdRjAdwDsR62B0ElV/YaI9AP4PoBB1Fp2fVJVw5pchgJYScNLjs/asl2ShuWhtl1HzTklsZNtZiu27DU747Rc0nBCjTj1AstT4XZRAHBhzH7vvfmwXQ9ucK9dR06N2n+rVqE4AAtzto+AvVdjl21ZdGounDhzfPCYOefIflt+O3pk0LTNL9vS7UuvhiXkSpudVNW7w5aJF73kHdsEI3enZrMSe7xJttZXN/Vc+SsAvqiq7wbwfgCfF5GbANwH4ClVPQbgqex3QsjbhHWDX1XHVPVU9vM1AGcAHARwF4CHs4c9DOBjm+UkIaT5bOhvfhEZBHArgGcA7FPVMaD2BgHA/sxGCNly1B38ItIL4DEAX1BV+4+9t847ISLDIjK8NO/9bUkIKZK6gl9EyqgF/ndV9YfZ8LiIDGT2AQATobmqelJVh1R1qLPH/i47IaRY1g1+qdV4ehDAGVX92hrT4wDuzn6+G8CPm+8eIWSzqCer73YAnwHwgog8l43dD+DLAB4VkXsAvA7gE/UsmFgZTGJLSmkp3PIqdbLK1K09Z88TsbWc1PAxddZadkrxrSzb2XQ3DNjztGTLmGJInKlXE9CRhypGliAALFTCGZoAgI6wVLn/4I3mlHcePWDavL2aWbH3Y75zNDg+NRtuGwcAqVM7L3H2ylF83QxIy5aqcw4bNfz88/7NrBv8qvoz2JUaP1T3SoSQLQW/4UdIpDD4CYkUBj8hkcLgJyRSGPyEREqx7bpgywaeRGGKJE6bKR9H6nNn5ZBXHB/Ve+8V21ZKbJsgLFNVUrs9VdXxY3rBnte5w/5G997t4eKTXT12RqI4mXaVZduPS1fsZFJL0lutOul5xh4C68hvObHORj9Br3E/eOUnJFIY/IRECoOfkEhh8BMSKQx+QiKFwU9IpBQq9b09yCGh5FRdvEwvD1fqq4SLjKYVO6tvWe3TYOKaM0/svnttSViaW03tzaomdnbeQsWed2nyqmmrGJJe6lz3qtWc2aKu9Jzvtd5MeOUnJFIY/IRECoOfkEhh8BMSKQx+QiKl0Lv9CkC34F3PhsnRVakRqtVw0gwApEvz4XG13+dnV+wnMDkXVg8AoJrYd/th1MFbqthrVRK7JuDYtN1GbXLWtqVWglRin/qpvb3u3f68L7XkSVDLqRSthVd+QiKFwU9IpDD4CYkUBj8hkcLgJyRSGPyERMq6Up+IHAbwHQD7UStudlJVvyEiDwD4LIDL2UPvV9Un1l1xiyt9zVbt8j7d1VVbYlteXrLXWw0n1CyrXR/v0pSdGLOwYtfOk8RpsVYN26auhaVIAHjp7IhpO3vuomlbcU7jpBT2o5KjFRbgt2ZLnDZfnjRnJnjlbkdXH/Xo/BUAX1TVUyKyDcCzIvJkZvu6qv59w14QQgqnnl59YwDGsp+vicgZAAc32zFCyOayob/5RWQQwK0AnsmG7hWR0yLykIjsbLJvhJBNpO7gF5FeAI8B+IKqzgL4JoAbARxH7ZPBV415J0RkWESGl+bttsiEkGKpK/il1vT9MQDfVdUfAoCqjqtqVVVTAN8CcFtorqqeVNUhVR3q7NnWLL8JIQ2ybvBLLevgQQBnVPVra8YH1jzs4wBebL57hJDNop67/bcD+AyAF0TkuWzsfgCfFpHjqKlZIwA+tyke/lbj1LNzMveWV2wZMEFY2ppZtCW78alZ0+b5KF76m1Fn8NLEFXPKpfHLpm0xtWVFKTnZhYb74tQSlJIjo6WO/OZ2AHNagBm21M3cs45Xv7hcz93+nyG8hetr+oSQLQu/4UdIpDD4CYkUBj8hkcLgJyRSGPyERMpvbbuuXEUR0fx6m+JILwJbKks8ycZ5blUJv6STM3bm3qIjHXqZe+rJXkbhzGVHwkzEyRJ0bOJk6CWWyWt55m2987q47dccH9Ww+TU6jTnelOvglZ+QSGHwExIpDH5CIoXBT0ikMPgJiRQGPyGRUrjUV1SvvrxSX661HFvJeb4dzltve7lsG9vsnnZzS2EpbXx62pwjZoYYoE5Pu6orv4Wft1cA00uKk5w98lJTRstXbDPxsvMcOc/rlWiu58wxC3h6hUmvg1d+QiKFwU9IpDD4CYkUBj8hkcLgJyRSGPyEREqxUp/m60tWpGyXh0Rs+aejzfa9rLZUdnnaLqq54vTqW6qE93Fu3p4DT7JzhDS/r2HYqgW/ltb5ZhXN9ObUbN48L3PPO+bGxgFPMq9fSueVn5BIYfATEikMfkIihcFPSKQw+AmJlHXv9otIJ4CnAXRkj/+Bqn5JRI4CeARAP4BTAD6jqiv+0dSs+7bFb+i7lNSuS6erdpusxYptuzBpb+Ulp/5cYmzkqlNvL3U230/E2hovmn8n3VAdcsxpzGaacikSzQiYeq78ywA+qKrvRa0d950i8n4AXwHwdVU9BmAawD0Ne0MIKYx1g19rzGW/lrN/CuCDAH6QjT8M4GOb4iEhZFOo629+ESllHXonADwJ4FUAV1X1jc+towAObo6LhJDNoK7gV9Wqqh4HcAjAbQDeHXpYaK6InBCRYREZXpqfCz2EENICNnS3X1WvAvhvAO8H0Cfy/x0iDgG4aMw5qapDqjrU2dPbiK+EkCaybvCLyB4R6ct+7gLwhwDOAPgpgD/JHnY3gB9vlpOEkOZTT2LPAICHRaSE2pvFo6r6HyLyEoBHRORvAPwSwIP1LJgnscdqreQl/LitkxzyJBF5yR5p6siATkJNJWm3bd57dmrJh159uXxSn9fWaqvjnR+exJZ6kqmzH968POdq3vN7LesGv6qeBnBrYPw11P7+J4S8DeE3/AiJFAY/IZHC4CckUhj8hEQKg5+QSJFmSAZ1LyZyGcC57NfdACYLW9yGfrwZ+vFm3m5+3KCqe+o5YKHB/6aFRYZVdagli9MP+kE/+LGfkFhh8BMSKa0M/pMtXHst9OPN0I8381vrR8v+5ieEtBZ+7CckUloS/CJyp4j8RkTOish9rfAh82NERF4QkedEZLjAdR8SkQkReXHNWL+IPCkir2T/72yRHw+IyIVsT54TkY8U4MdhEfmpiJwRkV+JyJ9l44XuieNHoXsiIp0i8nMReT7z46+z8aMi8ky2H98XETv1sx5UtdB/AEqolQF7B4B2AM8DuKloPzJfRgDsbsG6HwDwPgAvrhn7WwD3ZT/fB+ArLfLjAQB/XvB+DAB4X/bzNgAvA7ip6D1x/Ch0T1DLv+7Nfi4DeAa1AjqPAvhUNv6PAP60kXVaceW/DcBZVX1Na6W+HwFwVwv8aBmq+jSAqeuG70KtECpQUEFUw4/CUdUxVT2V/XwNtWIxB1Hwnjh+FIrW2PSiua0I/oMAzq/5vZXFPxXAT0TkWRE50SIf3mCfqo4BtZMQwN4W+nKviJzO/izY9D8/1iIig6jVj3gGLdyT6/wACt6TIormtiL4Q2VjWiU53K6q7wPwxwA+LyIfaJEfW4lvArgRtR4NYwC+WtTCItIL4DEAX1BVu0d58X4UvifaQNHcemlF8I8COLzmd7P452ajqhez/ycA/AitrUw0LiIDAJD9P9EKJ1R1PDvxUgDfQkF7IiJl1ALuu6r6w2y48D0J+dGqPcnW3nDR3HppRfD/AsCx7M5lO4BPAXi8aCdEpEdEtr3xM4APA3jRn7WpPI5aIVSghQVR3wi2jI+jgD2RWuHEBwGcUdWvrTEVuieWH0XvSWFFc4u6g3nd3cyPoHYn9VUAf9kiH96BmtLwPIBfFekHgO+h9vFxFbVPQvcA2AXgKQCvZP/3t8iPfwHwAoDTqAXfQAF+/D5qH2FPA3gu+/eRovfE8aPQPQHwHtSK4p5G7Y3mr9acsz8HcBbAvwHoaGQdfsOPkEjhN/wIiRQGPyGRwuAnJFIY/IRECoOfkEhh8BMSKQx+QiKFwU9IpPwfqiaj0PoUpWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Building a Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the first Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the second Dense layer (output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 591,384\n",
      "Trainable params: 591,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4:Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stage 5:Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 601s 12ms/sample - loss: 2.0464 - sparse_categorical_accuracy: 0.2399\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 515s 10ms/sample - loss: 1.7766 - sparse_categorical_accuracy: 0.3327\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 511s 10ms/sample - loss: 1.6462 - sparse_categorical_accuracy: 0.3505\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 512s 10ms/sample - loss: 1.5713 - sparse_categorical_accuracy: 0.3717\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 524s 10ms/sample - loss: 1.5210 - sparse_categorical_accuracy: 0.4137\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 526s 11ms/sample - loss: 1.4543 - sparse_categorical_accuracy: 0.4470\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 505s 10ms/sample - loss: 1.4011 - sparse_categorical_accuracy: 0.4605\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 502s 10ms/sample - loss: 1.3645 - sparse_categorical_accuracy: 0.4754\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 505s 10ms/sample - loss: 1.3583 - sparse_categorical_accuracy: 0.4815\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 509s 10ms/sample - loss: 1.3183 - sparse_categorical_accuracy: 0.4968\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 505s 10ms/sample - loss: 1.3012 - sparse_categorical_accuracy: 0.5037\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 1.2952 - sparse_categorical_accuracy: 0.510 - 503s 10ms/sample - loss: 1.2950 - sparse_categorical_accuracy: 0.5104\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 506s 10ms/sample - loss: 1.2667 - sparse_categorical_accuracy: 0.5189\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 508s 10ms/sample - loss: 1.2524 - sparse_categorical_accuracy: 0.5265\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 510s 10ms/sample - loss: 1.2601 - sparse_categorical_accuracy: 0.5262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd1162181d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 6 :Model evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 53s 5ms/sample - loss: 1.0784 - sparse_categorical_accuracy: 0.7411\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.741100013256073\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
